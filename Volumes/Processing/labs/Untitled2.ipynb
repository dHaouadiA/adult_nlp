{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding , Bidirectional , GlobalMaxPool1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import copy\n",
    "import re\n",
    "from nltk import WordNetLemmatizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train_data.csv')\n",
    "df_test=pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6251 entries, 0 to 6250\n",
      "Data columns (total 4 columns):\n",
      "url         6251 non-null object\n",
      "label       6251 non-null int64\n",
      "corpus      6251 non-null object\n",
      "dateTime    6251 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1563 entries, 0 to 1562\n",
      "Data columns (total 4 columns):\n",
      "url         1563 non-null object\n",
      "label       1563 non-null int64\n",
      "corpus      1563 non-null object\n",
      "dateTime    1563 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 48.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['corpus']=df_train['corpus'].apply(eval).apply(preprocessing_ap.listToString)\n",
    "df_test['corpus']=df_test['corpus'].apply(eval).apply(preprocessing_ap.listToString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_train['corpus'].values\n",
    "X_test=df_test['corpus'].values\n",
    "Y_train = np.asarray(df_train['label'].values).astype('float32')\n",
    "Y_test = np.asarray(df_test['label'].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "max_len = 150\n",
    "#It is the process of separating each word in a text as a unit and you can later\n",
    "#you use the tokenize data for things like term frequency and word clouds\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "#******************************\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,  201, 2228, ..., 1609,  757,  590],\n",
       "       [   0,    0,    0, ...,    0,    0, 1404],\n",
       "       [   0,    0,    0, ..., 2544, 1993, 3281],\n",
       "       ...,\n",
       "       [2250, 5202, 3746, ..., 1571,  198,   87],\n",
       "       [   8,   85, 1311, ...,  117,   30,    3],\n",
       "       [1292, 3706, 1966, ...,  697,  346,  378]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyBaseline_Model(maxlen,max_features):\n",
    "    embed_size = 128\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 150, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 150, 200)          183200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,763,401\n",
      "Trainable params: 2,763,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyBaseline_Model(max_len,max_words)\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asma\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\Asma\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1251 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 27s 5ms/step - loss: 0.5606 - accuracy: 0.7368 - val_loss: 0.3402 - val_accuracy: 0.7874\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 28s 6ms/step - loss: 0.3232 - accuracy: 0.8586 - val_loss: 0.4619 - val_accuracy: 0.7050\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 28s 6ms/step - loss: 0.2399 - accuracy: 0.9024 - val_loss: 0.5811 - val_accuracy: 0.6930\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 27s 5ms/step - loss: 0.2024 - accuracy: 0.9132 - val_loss: 0.6570 - val_accuracy: 0.7346\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 28s 6ms/step - loss: 0.1717 - accuracy: 0.9274 - val_loss: 1.1607 - val_accuracy: 0.6275\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 28s 6ms/step - loss: 0.1614 - accuracy: 0.9318 - val_loss: 0.7981 - val_accuracy: 0.7610\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 0.1543 - accuracy: 0.9322 - val_loss: 0.6869 - val_accuracy: 0.7218\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 31s 6ms/step - loss: 0.1449 - accuracy: 0.9368 - val_loss: 0.6086 - val_accuracy: 0.7362\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 0.1377 - accuracy: 0.9398 - val_loss: 0.5003 - val_accuracy: 0.7506\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 0.1362 - accuracy: 0.9396 - val_loss: 0.5518 - val_accuracy: 0.7538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a78d486f98>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2\n",
    "          #,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   74,  2488,   417, ...,   597,   935,    70],\n",
       "       [    0,     0,     0, ...,   278,   258,   613],\n",
       "       [    0,     0,     0, ...,  3663,   974,  1137],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    9,  2839,   205, ...,   303,   224,   116],\n",
       "       [ 1051, 12894,  3408, ...,  8110,  4044,  5072]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.461\n",
      "  Accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_sequences_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=predictions.reshape(1563,)\n",
    "predictions=list(map(lambda x: 1 if x > 0.5 else 0 , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.77      0.83       800\n",
      "         1.0       0.79      0.91      0.84       763\n",
      "\n",
      "    accuracy                           0.84      1563\n",
      "   macro avg       0.84      0.84      0.84      1563\n",
      "weighted avg       0.84      0.84      0.83      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapping_ap as sap\n",
    "import preprocessing_ap as pap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(url):\n",
    "    corpus=sap.scrap_raw_text(url)\n",
    "    corpus=pap.text_preprocessing(corpus)\n",
    "    tokenizer=pap.PatternTokenizer()\n",
    "    corpus=' '.join(corpus)\n",
    "    corpus=tokenizer.process_text(corpus)\n",
    "    corpus=[corpus]\n",
    "    c = tok.texts_to_sequences(corpus)\n",
    "    c = sequence.pad_sequences(c,maxlen=max_len)\n",
    "    prediction= model.predict(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping from https://www.xvideos.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asma\\Desktop\\internship\\mycode\\Volumes\\Processing\\scrapping_ap.py:24: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 24 of the file C:\\Users\\Asma\\Desktop\\internship\\mycode\\Volumes\\Processing\\scrapping_ap.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page)\n"
     ]
    }
   ],
   "source": [
    "predict('https://www.xvideos.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping from https://www.xvideos.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asma\\Desktop\\internship\\mycode\\Volumes\\Processing\\scrapping_ap.py:24: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 24 of the file C:\\Users\\Asma\\Desktop\\internship\\mycode\\Volumes\\Processing\\scrapping_ap.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page)\n"
     ]
    }
   ],
   "source": [
    "url=\"https://www.xvideos.com\"\n",
    "corpus=sap.scrap_raw_text(url)\n",
    "corpus=pap.text_preprocessing(corpus)\n",
    "tokenizer=pap.PatternTokenizer()\n",
    "corpus=' '.join(corpus)\n",
    "corpus=tokenizer.process_text(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " 'free',\n",
       " 'porn',\n",
       " 'video',\n",
       " 'xvideos',\n",
       " 'com',\n",
       " 'ie',\n",
       " 'endif',\n",
       " 'xvideos',\n",
       " 'com',\n",
       " 'search',\n",
       " 'best',\n",
       " 'free',\n",
       " 'porn',\n",
       " 'site',\n",
       " 'best',\n",
       " 'free',\n",
       " 'porn',\n",
       " 'site',\n",
       " 'search',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'm',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'sec',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'sec',\n",
       " 'k',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'min',\n",
       " 'view',\n",
       " 'subscription',\n",
       " 'ad',\n",
       " 'trend',\n",
       " 'tunisia',\n",
       " 'trend',\n",
       " 'xvideos',\n",
       " 'com',\n",
       " 'free',\n",
       " 'hosting',\n",
       " 'service',\n",
       " 'porn',\n",
       " 'video',\n",
       " 'convert',\n",
       " 'file',\n",
       " 'format',\n",
       " 'grab',\n",
       " 'embed',\n",
       " 'code',\n",
       " 'display',\n",
       " 'video',\n",
       " 'website',\n",
       " 'video',\n",
       " 'upload',\n",
       " 'show',\n",
       " 'index',\n",
       " 'day',\n",
       " 'upload',\n",
       " 'adult',\n",
       " 'video',\n",
       " 'upload',\n",
       " 'day',\n",
       " 'note',\n",
       " 'gay',\n",
       " 'shemale',\n",
       " 'video',\n",
       " 'filter',\n",
       " 'page',\n",
       " 'show',\n",
       " 'respective',\n",
       " 'category',\n",
       " 'page',\n",
       " 'host',\n",
       " 'w',\n",
       " 'xvideos',\n",
       " 'com',\n",
       " 'contain',\n",
       " 'absolutely',\n",
       " 'spyware',\n",
       " 'adware',\n",
       " 'trojan',\n",
       " 'etc',\n",
       " 'charge',\n",
       " 'hidden',\n",
       " 'charge',\n",
       " 'view',\n",
       " 'video',\n",
       " 'xvideos',\n",
       " 'rate',\n",
       " 'rta',\n",
       " 'label',\n",
       " 'parent',\n",
       " 'easily',\n",
       " 'block',\n",
       " 'access',\n",
       " 'site',\n",
       " 'information',\n",
       " 'xvideos',\n",
       " 'com',\n",
       " 'best',\n",
       " 'free',\n",
       " 'porn',\n",
       " 'video',\n",
       " 'internet',\n",
       " 'free',\n",
       " 'gen']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tok.texts_to_sequences(corpus)\n",
    "c = sequence.pad_sequences(c,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6457365 ],\n",
       "       [0.86379725],\n",
       "       [0.9799668 ],\n",
       "       [0.8671093 ],\n",
       "       [0.7482274 ],\n",
       "       [0.72045314],\n",
       "       [0.5577022 ],\n",
       "       [0.7022901 ],\n",
       "       [0.7482274 ],\n",
       "       [0.72045314],\n",
       "       [0.57713723],\n",
       "       [0.211813  ],\n",
       "       [0.86379725],\n",
       "       [0.9799668 ],\n",
       "       [0.64754987],\n",
       "       [0.211813  ],\n",
       "       [0.86379725],\n",
       "       [0.9799668 ],\n",
       "       [0.64754987],\n",
       "       [0.57713723],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.34388524],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.61725646],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.61725646],\n",
       "       [0.8814692 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.7253252 ],\n",
       "       [0.609673  ],\n",
       "       [0.47974885],\n",
       "       [0.50339264],\n",
       "       [0.44596946],\n",
       "       [0.61163497],\n",
       "       [0.44596946],\n",
       "       [0.7482274 ],\n",
       "       [0.72045314],\n",
       "       [0.86379725],\n",
       "       [0.6764616 ],\n",
       "       [0.6447208 ],\n",
       "       [0.9799668 ],\n",
       "       [0.8671093 ],\n",
       "       [0.48927635],\n",
       "       [0.32224107],\n",
       "       [0.49843067],\n",
       "       [0.83219385],\n",
       "       [0.4791219 ],\n",
       "       [0.55319595],\n",
       "       [0.7128086 ],\n",
       "       [0.8671093 ],\n",
       "       [0.6444065 ],\n",
       "       [0.8671093 ],\n",
       "       [0.9018944 ],\n",
       "       [0.5377996 ],\n",
       "       [0.76584154],\n",
       "       [0.7862977 ],\n",
       "       [0.9018944 ],\n",
       "       [0.986495  ],\n",
       "       [0.8671093 ],\n",
       "       [0.9018944 ],\n",
       "       [0.7862977 ],\n",
       "       [0.41079563],\n",
       "       [0.9370972 ],\n",
       "       [0.9190766 ],\n",
       "       [0.8671093 ],\n",
       "       [0.67324036],\n",
       "       [0.46766227],\n",
       "       [0.5377996 ],\n",
       "       [0.8764738 ],\n",
       "       [0.5919366 ],\n",
       "       [0.46766227],\n",
       "       [0.4542143 ],\n",
       "       [0.6138379 ],\n",
       "       [0.7482274 ],\n",
       "       [0.72045314],\n",
       "       [0.9052634 ],\n",
       "       [0.67110705],\n",
       "       [0.61220133],\n",
       "       [0.61220133],\n",
       "       [0.6790846 ],\n",
       "       [0.5505738 ],\n",
       "       [0.7180248 ],\n",
       "       [0.23798256],\n",
       "       [0.7180248 ],\n",
       "       [0.609673  ],\n",
       "       [0.8671093 ],\n",
       "       [0.7482274 ],\n",
       "       [0.88789177],\n",
       "       [0.92406565],\n",
       "       [0.640919  ],\n",
       "       [0.40060547],\n",
       "       [0.63990104],\n",
       "       [0.7012894 ],\n",
       "       [0.603275  ],\n",
       "       [0.64754987],\n",
       "       [0.3736142 ],\n",
       "       [0.7482274 ],\n",
       "       [0.72045314],\n",
       "       [0.211813  ],\n",
       "       [0.86379725],\n",
       "       [0.9799668 ],\n",
       "       [0.8671093 ],\n",
       "       [0.3800894 ],\n",
       "       [0.86379725],\n",
       "       [0.6644002 ]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
